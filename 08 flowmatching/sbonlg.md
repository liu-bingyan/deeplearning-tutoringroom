# Flow Matching and Schrödinger Bridges on Lie Groups: Literature Review

## Introduction

Generative modeling on manifolds and specifically on Lie groups has gained interest as many data domains are inherently non-Euclidean (e.g. rotations, shapes, and poses). Traditional score-based diffusion models assume Euclidean geometry, which complicates their direct application to manifold-valued data. Recent research has focused on extending continuous normalizing flows and diffusion processes to curved spaces, enabling geometric generative models that respect underlying symmetries. In parallel, the Schrödinger Bridge (SB) problem – an entropy-regularized optimal transport on path space – has emerged as a powerful framework for bridging two distributions with a stochastic process. SB approaches offer theoretical advantages (e.g. connection to optimal transport) but pose significant computational challenges. This review surveys core developments in flow matching and score-based diffusion models on manifolds and Lie groups, and examines nascent efforts to integrate these with Schrödinger Bridges. Key works are highlighted, along with theoretical/algorithmic challenges and open research directions, with an eye toward developing SB methods on Lie groups via flow matching.

## Flow Matching: From Euclidean to Manifolds and Lie Groups

Flow Matching (FM) is a recently introduced paradigm for training continuous normalizing flows without simulation. The idea is to define a family of simple probability paths from a base distribution $\mathfrak{X}_0$ (e.g. Gaussian noise) to the target distribution $\mathfrak{X}_1$, and then regress a vector field that "matches" these flows. Lipman et al. (2022) first proposed FM as a generalization of diffusion models: rather than relying on time-wise small noise perturbations, they train an ODE that transports noise into data along a chosen path. Notably, their framework allows using non-diffusive paths; for example, one can use optimal transport displacement interpolations as the intermediate trajectory between distributions. This yields faster training and sampling than standard diffusion, and even led to improved likelihoods and sample quality on ImageNet compared to denoising diffusion models. FM thus "opens the door" to continuous flows that achieve the effect of diffusion models but with potentially more efficient trajectories.

However, the original formulation of FM assumed Euclidean space where straight-line segments between points are well-defined. Extending FM to curved geometries required new ideas. Chen & Lipman (2023) introduced Riemannian Flow Matching (RFM) to handle general manifolds, replacing Euclidean straight lines with geodesic paths (or spectral approximations of geodesics when closed-form geodesics are unavailable). Their RFM approach avoids expensive simulation and even bypasses the need to compute divergence for CNF training, by constructing a suitable "premetric" that yields closed-form target vector fields. In practice, RFM can be "simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form". To deal with complex manifolds (e.g. meshes) they leverage spectral decompositions to approximate the metric, thereby generalizing FM beyond Euclidean space. This work demonstrated state-of-the-art results on non-Euclidean datasets and proved the viability of FM on Riemannian manifolds.

Very recently, Sherry & Smets (2025) took FM one step further by making it intrinsic to Lie groups. They observed that on a Lie group, the natural analog of a "straight line" in Euclidean space is an exponential curve (a geodesic obtained via the group exponential map). In Flow Matching on Lie Groups, they substitute line segments with exponential curves, yielding a simple and computationally efficient scheme for many matrix Lie groups. Crucially, common operations like group products, inverses, exponentials, and logarithms can be implemented with basic matrix computations, making the approach fast and intrinsic. Sherry & Smets show that FM on Lie groups can directly model data distributions that have components in Euclidean space and components on a Lie group (for example, an object's shape described by $\mathbb{R}^n$ and its pose in $SO(3)$). This method extends generative modeling to data on nonlinear group manifolds without sacrificing the elegance of the FM training objective.

In summary, the FM paradigm has evolved from Euclidean CNFs to geodesic FM on manifolds and now to Lie-group FM via exponential map, providing a toolkit for building continuous flow models that respect geometric constraints.

## Score-Based Diffusion Models on Manifolds and Lie Groups

Score-based generative models (SGMs) and denoising diffusion models (DDPMs) have also been extended to Riemannian manifolds, in parallel to the FM developments. Riemannian Score-Based Generative Modeling (De Bortoli et al., 2022) and Riemannian Diffusion Models (Huang et al., 2022) were pioneering works that defined diffusion processes on a manifold and learned to reverse them. These approaches showed that, in principle, one can perform score matching on a manifold by simulating a reference SDE (e.g. Brownian motion) on that manifold and learning the score (gradients of the log-density) with respect to the Riemannian volume. However, as noted in subsequent analyses, there are significant practical challenges. For instance, parameterizing a general vector field on an arbitrary manifold is non-trivial (one often needs local coordinates or a basis of tangent spaces), and performing Langevin updates or simulations requires projecting back to the manifold to enforce constraints. Indeed, "key challenges remain: parametrizing vector fields on general [manifolds] is unsolved, and Langevin updates require projection to preserve the manifold structure". Another limitation is computational: many manifold diffusion approaches rely on the manifold's heat kernel to define the forward noise distribution, which in general has no closed form. This can lead to expensive training procedures – e.g. needing to compute eigenfunctions or large matrix exponentials for each iteration – with cost growing exponentially in dimension for some spaces.

In summary, while the theory of diffusion-based generative modeling has been extended to curved spaces, the straightforward application often encounters high computational overhead and complexity in implementation. Lie groups (which are smooth manifolds with group structure) have received special attention because of their importance in domains like robotics, physics, and chemistry. A notable example is $SO(3)$, the group of 3D rotations. Jagvaral et al. (2023) established a unified framework for diffusion models on $SO(3)$, covering both the continuous SDE approach (score-based SDEs) and the discrete-time DDPM approach. They leverage the fact that $SO(3)$, being a compact Lie group, has a tractable heat kernel expressed via spherical harmonics/Wigner D-matrices. This allows efficient simulation of the forward diffusion (an $SO(3)$ Brownian motion converging to the uniform distribution) and training of the reverse process without prohibitive integrals. Their models achieved state-of-the-art results on synthetic orientation distributions and were applied to real tasks like pose estimation and modeling galaxy orientations, highlighting the practical value of diffusion on Lie groups.

Other works have proposed efficiency improvements for diffusion on symmetric spaces (which include many Lie groups like spheres and tori) by avoiding explicit heat kernel computation. For example, Mangoubi and Vishnoi (2024) introduced a diffusion method that projects Euclidean Brownian motion onto the manifold at each step, instead of using the exact manifold heat kernel, thereby reducing per-iteration complexity to polynomial time. Such approaches exploit the symmetry of the space to ensure the projected process behaves well (satisfying approximate Lipschitz conditions) and significantly bridge the gap between manifold diffusion and Euclidean diffusion in terms of efficiency.

Beyond diffusion-specific models, there are hybrid approaches that incorporate Lie group structure into the generative process. Bertolini et al. (2025), for instance, proposed Euclidean Generalized Score Matching for Lie groups. Rather than simulate a diffusion directly on the group (which might be complicated for non-compact or high-dimensional groups), they work in an embedding space: using a direct sum of Lie algebra representations to capture group components within a Euclidean latent space. This method learns the target distribution on a Lie group while still operating largely in $\mathbb{R}^n$ (augmented with group parameters), thus sidestepping some difficulties of manifold discretization. The authors proved that their process corresponds to solutions of a new class of coupled SDEs on the group. Experimentally, they showed improved performance on tasks like molecular conformer generation and ligand-receptor docking by modeling the global orientation (a $SO(3)$ transform) via their Lie group-aware method. Notably, their results outperformed naive Riemannian diffusion on the group, suggesting that choosing an appropriate Lie group representation can "enhance learning efficiency by reducing the effective dimensionality of the trajectory space". This echoes a recurring theme: incorporating symmetry and group structure (whether via explicit manifold diffusion or via embedding techniques) often yields better generalization and efficiency for generative models on non-Euclidean domains.

## Schrödinger Bridges in Generative Modeling

While flow matching and diffusion models focus on how to construct a mapping from a base distribution to the target, the Schrödinger Bridge (SB) framework asks a slightly different question: among all stochastic processes that transform a given initial distribution into a given final distribution over a fixed time horizon, which is the "closest" to a reference diffusion (in an entropy-relative sense)? The SB problem, originally posed by Schrödinger in 1932, is an entropy-regularized optimal transport (OT) problem on path space. In modern terms, given initial distribution $\mu_0$ and target distribution $\mu_1$ at time $T$, and a reference diffusion (e.g. an uncontrolled Brownian motion), the SB solution is a controlled diffusion process that matches $\mu_0$ and $\mu_1$ at the endpoints while minimizing the Kullback–Leibler divergence from the reference path measure. This yields a stochastic interpolation between $\mu_0$ and $\mu_1$ often called the entropic interpolation, which can be seen as the "most likely" random evolution connecting the two distributions.

In the context of generative modeling, SB methods provide a principled way to bridge a known prior (like Gaussian noise) and the data distribution in finite time, with the added benefit of closeness to an OT plan. De Bortoli et al. (2021) were among the first to connect SB with score-based models, proposing the Diffusion Schrödinger Bridge (DSB) algorithm. DSB is an iterative method inspired by the Sinkhorn algorithm for entropic OT: it alternates between forward and backward diffusion processes that correct the marginal constraints. The remarkable insight of De Bortoli et al. was that the first iteration of DSB is equivalent to training a standard diffusion model (as in Song et al., 2021) with a sufficiently long forward noising time. Each subsequent iteration introduces an adjustment to the drift terms to better satisfy the end-point distributions, gradually reducing the discrepancy between the forward process's final distribution (which starts at $\mu_0$) and the target $\mu_1$, and likewise between the backward process's start distribution and $\mu_0$. In other words, a single round of score-based diffusion is an approximation to the SB solution, and running more iterations moves the generative process closer to the true entropic OT solution.

The DSB framework demonstrated that SB can serve as a unifying theory: it recovers diffusion models as a special case (one iteration) and can potentially improve upon them by converging to the optimal bridge. Indeed, DSB was shown to generate the data distribution in finite time (instead of requiring time $\to\infty$ for the distribution to approach Gaussian as in classic diffusion), and was touted as the continuous-state analog of the Sinkhorn algorithm for OT.

Building on these ideas, subsequent works have aimed to improve the efficiency and stability of SB algorithms in high dimensions. One challenge is that naive implementations of SB (e.g. using iterative proportional fitting on time-discretized paths) can be extremely slow or unstable, as error may accumulate across iterations. Shi et al. (2023) introduced Iterative Markovian Fitting (IMF) and a practical algorithm called Diffusion Schrödinger Bridge Matching (DSBM) to address these issues. DSBM formulates each SB iteration in a way that avoids propagating errors forward: essentially, they fit local "bridge" dynamics in a single sweep rather than repeatedly simulating forward and backward processes to convergence. Importantly, Shi et al. highlight that "while Denoising Diffusion Models (DDMs) and Flow Matching Models (FMMs) implement transports via an SDE or ODE, they are not guaranteed to be close to the true optimal transport map", whereas Schrödinger Bridges do recover an entropy-regularized OT. Their DSBM method significantly improved the scalability of SB computations and was shown to encompass many recent transport algorithms as special or limiting cases. In effect, DSBM bridges the gap between purely stochastic transports (diffusions) and the more deterministic OT map, offering a continuum between them by adjusting the entropy regularization.

Another notable extension is the Reflected Schrödinger Bridge by Deng et al. (2024), which tackles constrained domains. In many applications, data lie in a bounded region of $\mathbb{R}^n$ or a manifold with boundary. Standard diffusion would then require ad-hoc steps to keep samples in range. Deng and colleagues derive SB dynamics where the forward and backward SDEs are subject to reflection conditions at the boundaries (Neumann or Robin boundary conditions). They also extend the usual training objective (which involves a divergence or score matching) to account for the bounded support. The reflected SB algorithm was shown to produce robust generative models in bounded domains without resorting to artificial thresholding. This is a clear step toward SBs on general spaces, as it required handling geometry (boundary conditions) explicitly in the stochastic process.

In summary, Schrödinger Bridge methods provide a compelling framework for generative modeling: they unify diffusion models with OT, guaranteeing (in theory) a process that is closest to the optimal transport between prior and data. Significant progress has been made in making SB algorithms more practical and extending them to constrained or complex supports. These developments suggest it is increasingly feasible to leverage SBs to generate samples in difficult settings that diffusion or flow models alone might struggle with. The natural next question is how to apply these ideas to manifold-valued data, in particular to Lie groups, by capitalizing on the advances in flow matching and diffusion on those spaces.

## Towards Schrödinger Bridges on Lie Groups

Thus far, there has been relatively little published work directly addressing Schrödinger Bridges on manifolds or Lie groups in the machine learning literature, which makes it a promising area for new research. The SB problem itself is well-defined on any state space where one can define a reference diffusion process. In a Riemannian manifold setting, the reference can be taken as the Brownian motion on the manifold (governed by the Laplace–Beltrami operator), and theoretical studies have noted that SB solutions can be characterized via analogous equations as in the Euclidean case (a pair of Schrödinger-type PDEs or Hamilton–Jacobi-Bellman equations). However, solving these equations or implementing the iterative SB algorithm on a manifold poses new difficulties. Many of the challenges mirror those encountered in manifold diffusion models, now compounded by the need to enforce two endpoint distributions simultaneously. For example, computing the transition densities or score functions on a Lie group may require eigen-decompositions of the Laplacian on that group (as done for $SO(3)$), which becomes intractable for large or high-dimensional groups. Moreover, the iterative proportional fitting nature of SB algorithms means we might need to alternate between forward and backward passes on the manifold multiple times – if each pass is expensive (due to geodesic calculations or density evaluations), the overall procedure could be extremely slow. Early SB implementations in Euclidean space already noted scaling issues, so a direct extension to manifolds would likely suffer similarly or worse without new innovations.

One promising strategy is to combine flow matching techniques with SB iterations to leverage the best of both worlds. Notably, the DSBM algorithm by Shi et al. (2023) was conceptually close to performing a flow matching at each iteration – they fit a time-dependent drift that transports one distribution to another in a single shot before iterating. This idea could be transplanted to a Lie group setting: use Flow Matching on Lie Groups as a subroutine within the SB algorithm. Concretely, suppose we want to compute a Schrödinger Bridge on a Lie group connecting $\mu_0$ to $\mu_1$. We could initialize with a reference process (e.g. a Brownian motion on the group that approximately connects $\mu_0$ to $\mu_1$ in distribution at time $T$). Then, in each SB iteration, rather than simulating data and doing endpoint condition correction naïvely, we could train a vector field on the Lie group (via FM on Lie groups) that transports the current forward trajectory's endpoint distribution to the target $\mu_1$. Because FM on Lie groups provides an intrinsic, fast way to parameterize flows using the exponential map, this could substantially accelerate the fitting of SB bridging dynamics. Essentially, the SB iterative update could be turned into a sequence of flow-matching problems on the Lie group, each solved by leveraging the tools from Sherry & Smets (2025) or related methods. The "exponential curve" approach of FM on Lie groups means we can efficiently adjust the drift in the group space to hit the desired endpoint in one go, rather than slowly diffusing over many small steps. This is an appealing direction because it unites the OT accuracy of Schrödinger Bridges with the one-shot efficiency of flow matching. We expect such a method to produce a controlled diffusion on the Lie group that exactly matches the prior $\mu_0$ and data $\mu_1$ at endpoints, with minimal entropy cost. Additionally, it would automatically respect the group's geometry (since all transports are done via group operations) and could exploit any algebraic simplifications available (e.g. for matrix Lie groups).

Of course, open challenges remain in realizing Schrödinger Bridges on Lie groups. A fundamental issue is that not all Lie groups have easy-to-sample reference diffusions or known heat kernels (unlike $SO(3)$ which is relatively special). For instance, non-compact groups like the Euclidean group $SE(3)$ (translations and rotations) or $SL(n)$ might require careful treatment of drift to prevent divergent behavior. One may need to truncate time or constrain the process in practice. Moreover, integrating the SB dual equations (analogous to the forward/backward Kolmogorov PDEs) on a manifold might require numerical solvers on meshes or grids, which could be high-dimensional. Another challenge is expressiveness vs. efficiency: using neural networks to represent the SB's density correction factors or drifts on a manifold is possible, but these networks must handle manifold-valued inputs – a topic of ongoing research (e.g. constructing equivariant neural architectures on Lie groups). The convergence behavior of SB algorithms on manifolds is also largely unexplored; it's unclear how many iterations are needed or how robust iterative fitting is when the underlying space has curvature. Each iteration might introduce approximation error (if using finite samples or approximate geodesics), and analyzing or controlling this error on a Lie group is an open problem.

## Challenges and Open Problems

Several theoretical and practical challenges are highlighted across the literature:

### Parameterization of Manifold Dynamics
Learning functions like drift fields or score functions on a general manifold is difficult. There is no universal parametrization for tangent vector fields on arbitrary manifolds, and charts or embeddings must be used. This can introduce projection errors or redundancy. Recent approaches mitigate this by working in ambient Euclidean space or using group representations, but a fully general solution remains open.

### Computational Costs
Many manifold methods rely on quantities that lack closed form (geodesics, exponential maps, or heat kernels). As a result, training can be orders of magnitude slower than in $\mathbb{R}^n$. Techniques like spectral approximations or Brownian projection help, but scaling to high dimensions (or complex groups like $SU(N)$) is still challenging. Efficient algorithms for sampling and density estimation on manifolds are needed to make SB and diffusion models practical in these cases.

### Schrödinger Bridge Iterations
SB algorithms historically suffer from slow convergence or instability, especially in high dimensions. Each iteration must solve a forward and backward diffusion problem. Improvements like DSBM reduce error accumulation, but when extending to Lie groups one must ensure that each iterative update can be computed with sufficient accuracy. Investigating convergence guarantees and error bounds for SB on manifolds is an open theoretical question.

### Combining SB with FM/Diffusion
The idea of integrating flow matching into SB on Lie groups is promising but untested. Open questions include how to initialize the reference process on a group (e.g. choose an appropriate prior on the Lie group), how to represent the dual potentials or correcting factors on the group, and how to enforce group constraints throughout training. Developing a unified framework that merges FM, diffusion, and SB for manifolds could yield efficient algorithms that naturally generalize many of the methods discussed (similar to how DSBM unified diffusion and flow matching in Euclidean space).

### Exploiting Symmetry and Geometry
Lie groups come with rich symmetry (e.g. invariances, conjugacy classes) that can be exploited. An open research direction is to design equivariant generative models that incorporate these symmetries so that the learned dynamics commute with group actions. While some work has been done on equivariant flows and diffusion, applying these principles in the context of SB (which itself is an OT problem) could improve efficiency and interpretability. Additionally, understanding how curvature or topological features of the manifold influence generative performance (e.g. does negative curvature cause diffusions to spread too fast? does topology create multi-modal issues?) is largely unexplored.

Open problems remain at the intersection of optimal transport, geometry, and generative modeling. For example, extending the theory of entropic OT to geodesic spaces suggests that SB might provide a notion of distance or curvature on manifold probability spaces – investigating this for Lie groups could connect to broader questions in geometric statistics. On the algorithmic side, a major open goal is to develop Schrödinger Bridge methods that are as scalable and easy-to-train as current diffusion models, but applicable to manifold-valued data. This likely requires innovations in network architecture (to represent manifold functions), numerical methods (to handle PDEs on manifolds or simulate stochastic flows accurately), and perhaps new theoretical insights that simplify the SB equations under certain symmetries.

## Conclusion

In this literature review, we covered the trajectory from flow matching in Euclidean space to its extensions on Riemannian manifolds and Lie groups, and we surveyed the parallel progress of score-based diffusion models on these geometric domains. We also reviewed Schrödinger Bridges, which offer an appealing OT-consistent approach to generative modeling, and discussed recent advances that make SBs more practical. Bringing these threads together, making flow matching and Schrödinger bridges work on Lie groups is an exciting frontier. The core components are now coming into place: we have methods to handle continuous flows on Lie groups efficiently and we have algorithms to solve SB problems in standard settings. The next step is to combine them, leveraging the Lie group structure to enforce geometry while using SB formalisms to ensure optimal transport properties. Success in this direction could enable generative models that are both geometrically aware and OT-optimal, opening up new applications in physics (e.g. sampling from molecular rotational distributions), robotics (motion planning under uncertainty on $SE(3)$), and beyond. The literature highlights many challenges – from computational cost to theoretical convergence – but it also provides strong motivation and tools to tackle them. As research continues, we expect to see Schrödinger Bridge methods on manifolds and Lie groups become an active area, with flow matching playing a key role in unlocking their potential. Each piece of work reviewed here contributes part of the puzzle, and together they point to a rich landscape of open research opportunities at the intersection of deep generative modeling, differential geometry, and optimal transport.

## References
(References are cited inline throughout the text)