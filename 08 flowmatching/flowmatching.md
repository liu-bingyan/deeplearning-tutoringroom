# Flow Matching in Generative Modeling: A Technical Introduction

## 1. Introduction and Motivation

Generative modeling aims to transform a simple base distribution (e.g. Gaussian noise) into a complex data distribution. Traditional approaches include normalizing flows (learn an invertible transformation with tractable density) and diffusion models (gradually perturb data with noise and then reverse the process using learned score functions). Each has limitations: Continuous Normalizing Flows (CNFs) require costly ODE integration during training and Jacobian-determinant computations, while diffusion models need many simulation steps for sampling.

Flow Matching (FM) is a recently introduced paradigm that combines strengths of CNFs and diffusion models to alleviate these issues. The core idea of FM is to directly train a continuous flow (ODE) model without simulation, by regressing a time-dependent vector field to match a prescribed evolution (or probability flow) between the base and data distributions. This approach allows training CNFs at unprecedented scale, providing a stable and simulation-free alternative to diffusion model training.

Original Flow Matching Model: Introduced by Lipman et al. (2023), FM formulates generative modeling as learning an ODE that carries $p_0$ (e.g. a noise prior) to $p_1$ (the data distribution) over time $t\in[0,1]$. Instead of maximum likelihood, FM uses a direct regression objective on the continuous vector field. Intuitively, we prescribe a family of intermediate distributions $p_t$ connecting $p_0$ and $p_1$, and then train a velocity field $u_\theta(t,x)$ such that following $\dot{x}=u_\theta(t,x)$ transports samples according to that path. Formally, one seeks $u_\theta(t,x)$ to minimize the mean squared error against an ideal vector field $u^*(t,x)$ that yields the desired interpolation $p_t$. The FM loss can be written as:

$$L(\theta) = \mathbb{E}_{t\sim U(0,1)} \mathbb{E}_{x\sim p_t} [\|u_\theta(t,x) - u^*(t,x)\|^2],$$

which trains $u_\theta(t,x)$ to match $u^*(t,x)$ for all times. In essence, "we're just performing regression on $u_t(x)$ for all $t$" instead of doing iterative simulations. By eliminating expensive ODE solves during training, FM makes it feasible to train large CNFs much faster while still exactly modeling the continuous-time transformation between distributions.

Motivation: This simulation-free strategy addresses key pain points. Normalizing flows are powerful (they can represent complex distributions by continuously deforming a base density), but training them via maximum likelihood requires integrating $\dot{x}=u_\theta(t,x)$ forward for each data sample and computing $\nabla\cdot u_\theta$ (divergence) to evaluate density changes. FM sidesteps this by directly supervising the vector field without requiring on-the-fly integration or density evaluation. Meanwhile, diffusion models rely on stochastic simulation with many small steps; FM offers a deterministic ODE alternative that can be integrated with large steps (even off-the-shelf ODE solvers) to generate samples quickly. In fact, using FM with a diffusion-like path yields a more robust and stable training procedure for diffusion models. In summary, flow matching promises fast training, fast sampling, and high fidelity by learning an optimal continuous flow from noise to data.

## 2. Continuous Normalizing Flows (CNFs) Background

To understand flow matching, we first review continuous normalizing flows. A CNF defines a smooth invertible mapping $x(0)\sim p_0 \mapsto x(1)\sim p_1$ via an ODE: $\frac{d}{dt}x(t) = v(t,x(t))$, with a time-dependent velocity field $v(t,x)$ (usually parameterized by a neural network). Solving this ODE from $t=0$ to $1$ carries an initial sample $x(0)$ to a final sample $x(1)=\phi(x(0))$, where $\phi$ is the flow map. The continuity equation relates the evolving density $p_t(x)$ to the velocity field:

$$\partial_t p_t(x) = -\nabla_x \cdot (p_t(x)v(t,x)). \quad (1)$$

This is a PDE stating that as points move under $v(t,x)$, the density changes according to the divergence of the flow. Equivalently, one can derive an instantaneous change-of-variable formula for densities: if $x(t)$ follows the flow, the log-density satisfies $\frac{d}{dt}\log p_t(x(t)) = -\nabla_x\cdot v(t,x(t))$. Integrating from $0$ to $1$, one obtains the change in log-density induced by the flow. In particular, if $x(1)=\phi(x(0))$, then:

$$\log p_1(\phi(x_0)) = \log p_0(x_0) - \int_0^1 \nabla_x \cdot v(t,x(t))dt,$$

which is the continuous analog of the formula for normalizing flows with Jacobian determinants. This allows evaluating $p_1$ given $p_0$ and the path $\phi$, and thus enables maximum-likelihood training of CNFs by backpropagating through the ODE (as done in Neural ODE frameworks).

Training CNFs via Maximum Likelihood: In practice, one would choose $v(t,x;\theta)$ and optimize $\theta$ so that for all data $x_1\sim p_1$, the above equation holds – i.e. $\log p_1(x_1)$ is maximized (or equivalently the KL divergence $D_{\mathrm{KL}}(p_1 | p_\theta(1))$ is minimized). This requires repeatedly solving the ODE for different initial samples to compute the loss, and also computing the divergence $\nabla\cdot v$ along the path. Techniques like the instantaneous change of variables (Chen et al. 2018) make this feasible, but the procedure is still very slow due to needing many fine time steps for accuracy. Additionally, estimating $\nabla\cdot v$ in high dimensions can be challenging (though trace-estimation or Hutchinson tricks exist). These difficulties have limited the scalability of CNFs in practice.

Key idea of Flow Matching: If we could somehow know the correct vector field $v(t,x)$ that transforms $p_0$ into $p_1$, we could try to learn it directly by regression, rather than via likelihood. That is exactly the insight behind flow matching: avoid the expensive inner ODE solves by constructing a training signal for $v(t,x)$ at each $(t,x)$ without having to explicitly integrate the flow. This requires specifying the desired probability path $p_t$ between $p_0$ and $p_1$ and computing the corresponding ideal velocity field $u^*(t,x)$ that satisfies (1). Once we have a target $u^*(t,x)$ for every point in time and space, we can train $u_\theta(t,x)$ to approximate it by simple supervised learning.

However, two challenges arise:
1. There is generally no unique velocity field that transports $p_0$ to $p_1$ – there are infinitely many possible paths (think of many different "routes" connecting the same start and end distributions). We need to choose a specific path $p_t$ (and thus $u^*$) that is convenient or optimal.
2. Even if we fix a desired $p_t$, how do we determine $u^*(t,x)$ without already solving the generative problem? We obviously do not know the true $p_t$ in closed form for arbitrary data.

The solution to both issues comes from introducing an auxiliary conditional viewpoint.

## 3. Flow Matching: Formulation and Training

Conditional Probability Paths: Flow Matching introduces a latent variable interpretation: express the interpolating distribution $p_t$ as a marginal of a joint distribution that conditions on either the initial or final state. Concretely, one can formalize a random coupling between $X(0)\sim p_0$ and $X(1)\sim p_1$, and define a stochastic process $X(t)$ for $t\in[0,1]$ such that $X(0)=X_0$, $X(1)=X_1$. We design the conditional law of $X(t)$ given the endpoints $X(0)=x_0, X(1)=x_1$ in a simple way (for example, a linear interpolation plus some noise). By construction, at $t=0$ and $t=1$ the marginals are correct ($X(0)\sim p_0$, $X(1)\sim p_1$). At any intermediate time $t$, the marginal $p_t$ is then:

$$p_t(x) = \int p_t(x|x_0,x_1) p(x_0,x_1) dx_0 dx_1,$$

where $p(x_0,x_1)$ is the joint distribution of the endpoints and $p_t(x|x_0,x_1)$ is the conditional distribution at time $t$.

Gaussian Stochastic Interpolants: A popular choice of conditional path is the Gaussian bridge. For example, one can define $X(t)$ (given endpoints $X(0)=x_0$, $X(1)=x_1$) to be a linear interpolation with additive Gaussian noise. Formally, let 

$$p_t(x|x_0,x_1) = \mathcal{N}(x; \mu_t(x_0,x_1), \sigma_t^2 I),$$

where the mean $\mu_t(x_0,x_1)$ and variance $\sigma_t^2$ are chosen such that $\mu_0 = x_0$, $\mu_1 = x_1$ and $\sigma_0 = 0$, $\sigma_1 = 0$. One simple choice is $\mu_t(x_0,x_1) = (1-t)x_0 + tx_1$ (linear interpolation of the positions) and $\sigma_t^2$ perhaps peaking at mid-times and vanishing at the ends. For instance, we might let $\sigma_t^2 = \alpha,t(1-t)$ for some scale $\alpha$, so that $X(t)$ is distributed around the straight line from $x_0$ to $x_1$ with maximal diffusion in the middle. Under such a model, $p_t(x)$ becomes a convolution of $p_0$ and $p_1$ – in fact, $p_t$ will be a mixture of Gaussians centered along the line from random $x_0$ to random $x_1$. This family of Gaussian probability paths includes diffusion-like processes as a special case (where $x_1$ is essentially ignored, as in the forward noise perturbation of diffusion models).

Target Vector Field: Given the conditional law, one can derive the instantaneous drift $u^*(t,x|x_1)$ that would yield the evolution $p_{t|0,1}$ for each conditioned pair. In our Gaussian bridge example, the drift turns out to have a nice form: it is essentially the sum of two terms accounting for how the mean and variance change in time. In particular, for a Gaussian conditional $p_{t|1}(x|x_1)=\mathcal{N}(\mu_t(x_1),\sigma_t(x_1)^2I)$, one finds

$$u^*(t,x \mid x_1) = \frac{\dot{\sigma}_t}{\sigma_t} \big(x - \mu_t(x_1)\big) + \dot{\mu}_t(x_1). \tag{2}$$

As a check, if we take the simplest case of deterministic linear interpolation with $\mu_t(x_1)=t,x_1$ and $\sigma_t\equiv0$, then $\dot{\mu}_t = x_1$ and $\dot{\sigma}_t/\sigma_t$ is formally $\frac{-1}{1-t}$ (interpreting $\sigma_t\to0$), so (2) yields $u^*(t,x|x_1)=\frac{x_1 - x}{1-t}$, meaning move $x$ straight toward $x_1$ at a speed inversely proportional to the remaining time – which indeed will carry $x$ to exactly $x_1$ by time $t=1$. More generally, Equation (2) provides the target vector field that realizes the chosen probability path. Finally, to get the unconditional marginal field $u^*(t,x)$ that appears in the loss, we average out the conditioning on $x_1$:

$$u^*(t,x) = \mathbb{E}_{x_1\sim p_1} [u^*(t,x \mid x_1) \mid X(t)=x].$$

In practice this expectation is implemented by sampling an $x_1$ when we sample $x$ (via the coupling). In other words, whenever we sample an $x$ at time $t$, we know it came from some pair $(x_0,x_1)$, so we can use that $x_1$ to compute the drift $u^*(t,x|x_1)$.

Training Algorithm: With this setup, flow matching training proceeds as follows:
1. Sample a random time $t\sim \mathcal{U}(0,1)$.
2. Sample an initial-point $x_0\sim p_0$ (e.g. $x_0 \sim \mathcal{N}(0,I)$ if $p_0$ is standard normal) and an endpoint $x_1\sim p_1$ (draw a random data sample).
3. Sample an intermediate point $x_t$ from the conditional bridging distribution $p_{t\mid 0,1}(\cdot \mid x_0,x_1)$. For example, take $x_t = \mu_t(x_0,x_1) + \sigma_t \xi$ with $\xi\sim \mathcal{N}(0,I)$ if using a Gaussian path.
4. Compute the target drift $u^*(t,x_t\mid x_1)$ using the formula designed for your path (e.g. Equation (2)).
5. Update the neural network parameters $\theta$ by taking a gradient step to reduce $|u_\theta(t,x_t) - u^*(t,x_t\mid x_1)|^2$.

This stochastic training loop provides unbiased estimates of the loss above. Over many iterations, $u_\theta(t,x)$ will converge to the vector field that transports $p_0$ to $p_1$ along the chosen path. At convergence, one can generate new data samples by simply drawing $x(0)\sim p_0$ and solving the ODE $\dot{x}=u_\theta(t,x)$ up to $t=1$. Because our learned $u_\theta$ approximates $u^*$, the distribution of $x(1)$ will match $p_1$. Importantly, we can use a standard ODE solver with adaptive step sizes or a large step discretization since the learned trajectory is smooth, allowing much faster sampling than simulation of thousands of tiny diffusion steps.

Practical Considerations: The conditional path $p_{t|0,1}$ is a design choice. Simpler choices (like independent or near-independent paths) make the regression task easier but might not yield the globally optimal transport. The original FM work suggested using a diffusion path (i.e. $p_t$ similar to the forward noising of diffusion models) for stability, or an optimal transport path for efficiency. We discuss these variants next. Also, note that while each conditional path in training ends exactly at its sampled $x_1$, the learned ODE may not send every $x_0$ to a specific $x_1$ – it will learn an averaged effect that reproduces $p_1$ in distribution. As long as $p_t$ were chosen such that its marginal $p_1$ is exactly the data distribution (which is ensured if we always condition on a real $x_1\sim p_1$), the final learned flow will match $p_1$. In practice, FM is found to be robust: even if the chosen $p_{t|0,1}$ is not the true geodesic path, the neural $u_\theta$ can still learn to transform the distribution correctly.

Next, we look at some key developments built on top of this framework.

## 4. Key Developments and Variants

### 4.1 Probability Flow ODEs and Diffusion Connections

One notable special case of flow matching is when the path $p_t$ is chosen to mimic the diffusion model trajectory. In score-based diffusion models, one typically forwards the data $p_1$ into a noise distribution $p_0$ by adding Gaussian noise gradually (governed by an SDE), and then learns to reverse that process. It was shown (Song et al., 2020) that the reverse SDE has an equivalent deterministic ODE called the probability flow ODE, which shares the same marginal densities $p_t$ as the stochastic process. This ODE has the form: 

$$\frac{d}{dt}x(t) = f(t,x) - \frac{1}{2}g(t)^2 \nabla_x \log p_t(x),$$

where $f(t,x)$ and $g(t)$ come from the SDE's drift and diffusion coefficients, and $\nabla_x \log p_t(x)$ is the score function of the intermediate distribution. The probability flow ODE gives a smooth transformation from pure noise to data, and in fact it is a CNF (with $v(t,x)=f(t,x)-\frac{1}{2}g^2(t)\nabla_x \log p_t(x)$). It inherits all the properties of an ODE flow – including invertibility and the ability to compute likelihoods if needed. The trajectories of this ODE are much less noisy than the diffusion paths, yet they lead to the same distribution at $t=1$.

Flow Matching vs. Score Matching: If we know the score $\nabla_x \log p_t(x)$ for each $t$, we could simulate this ODE to sample data. In practice, diffusion models train a neural network $s_\theta(t,x)\approx \nabla_x \log p_t(x)$ by score matching. Flow matching offers an alternative: we can directly train a neural ODE to follow the same probability flow. Concretely, if we set $p_{t|0,1}(x|x_0,x_1)$ to ignore $x_1$ altogether and simply evolve $x_0\sim p_0$ forward with the same SDE (this is equivalent to the usual diffusion forward process from data to noise, but run backward), then $u^*(t,x)$ becomes exactly $f(t,x)-\frac{1}{2}g^2(t)\nabla \log p_t(x)$. In other words, flow matching with a diffusion path will train $u_\theta(t,x)$ to approximate the probability flow ODE's drift. This is a more direct training signal than score matching: rather than learning the score and then constructing the ODE, we learn the ODE that moves along the diffusion's probability flow in one go. Lipman et al. report that this approach is more robust and stable than traditional diffusion training, likely because it avoids relying on the quality of score estimates in low-density regions (a notorious difficulty in diffusion). In essence, FM bridges score-based models and CNFs: if one uses the "diffusion" choice of $p_t$, FM recovers a deterministic formulation of the diffusion model. This connection also explains why both frameworks reach the same theoretical minimum: the probability flow ODE and the reverse-time SDE produce the same $p_1$ when $s_\theta=\nabla \log p_t$ or $u_\theta=u^*$. Likelihood Computation: A bonus of working with an ODE (as in flow matching or probability flow ODEs) is that one can compute exact data likelihoods by integrating the divergence (see Eq. (1)). Diffusion models usually do not provide a tractable likelihood. With flow matching, if needed, one can evaluate $\log p_1(x_1)$ for a given sample by integrating the learned divergence $\nabla\cdot u_\theta(t,x(t))$ along the trajectory. In the diffusion case, this recovers the ODE-based log-likelihood that was introduced by Song et al. (2020). Empirically, FM trained models have shown better likelihoods and sample quality than analogous diffusion models, suggesting that directly learning the flow (rather than the score) can be advantageous.

### 4.2 Rectified Flow: Straighter Paths for Faster Generation

Another key variant is Rectified Flow, proposed by Liu, Gong, and Liu (2023). Rectified flow specifically aims to make the learned trajectories as straight as possible in space, thereby minimizing the path length between $p_0$ and $p_1$. The motivation is that straight paths are the shortest paths between two points, so if the ODE follows (nearly) straight lines, one can traverse them with very few integration steps (in the extreme, a single step from $x_0$ to $x_1$) Rectified Flow uses the flow matching framework but augments it by cleverly choosing or iteratively improving the coupling between $p_0$ and $p_1$. In standard FM (as described above), we sampled $x_0$ and $x_1$ independently. Rectified Flow instead tries to find a better pairing between noise samples and data samples so that $x_0$ and $x_1$ are likely to lie along a straight line. For example, if $p_0$ is standard Gaussian, one might want to couple each data point $x_1$ with a noise sample $x_0$ that is "aligned" with it. Rectified Flow's algorithm, in simplified terms, works by iterative refinement called rectification: start with an arbitrary coupling (e.g. independent), train a flow $u_\theta$; then use the learned flow to induce a new coupling (by transporting $p_0$ samples halfway or so toward $p_1$ and re-matching), and train again. Each iteration produces straighter paths and lowers the overall transport cost between $p_0$ and $p_1$. The authors prove that this procedure leads to non-increasing convex transport costs, meaning it converges toward the optimal (shortest) coupling. In practice, after a few rectification rounds, the learned ODE can generate high-quality samples with a very coarse discretization – even as low as 1 or 2 Euler steps for image synthesis tasks. This is a remarkable efficiency gain. Rectified Flow essentially merges ideas from optimal transport into flow matching: it seeks the straightest displacement field between distributions. One can view the rectified flow ODE as approaching the true Wasserstein geodesic (optimal transport map) between $p_0$ and $p_1$. Indeed, the straight-line paths found are reminiscent of optimal transport maps under quadratic cost. The difference is that Rectified Flow learns these paths via regression (no expensive OT solve in high-dimensions) and can handle unpaired domain transfer. In their paper, they demonstrate not only generative modeling (noise $\to$ data) but also domain transfer ($\pi_0 \to \pi_1$ for two different data domains) using the same framework. In summary, Rectified Flow shows that by encouraging geodesic paths (shortest paths), one can drastically reduce the number of function evaluations (NFEs) needed at inference, obtaining "flow straight and fast" results.

### 4.3 Optimal Transport Paths in Flow Matching

From the outset, the Flow Matching paper noted that we are free to choose any reasonable probability path $p_t$ between $p_0$ and $p_1$. A natural choice is the Optimal Transport (OT) displacement interpolation – i.e. the constant-speed geodesic under the Wasserstein-2 metric (which for Euclidean space is given by linear interpolations along the optimal coupling of $p_0$ and $p_1$). Such a path minimizes the quadratic transport cost and often yields nice straight trajectories. Lipman et al. observed that using OT-based conditional paths in FM leads to faster training convergence and better generalization than diffusion-like paths. In particular, they reported improved likelihoods and sample quality on ImageNet by using OT displacement interpolations. The catch is that a priori one may not know how to couple $p_0$ and $p_1$ by OT (especially in high dimensions). Nonetheless, this idea spurred research into approximating OT during training. Minibatch Coupling: One practical approach is to compute an approximate OT coupling on minibatches. Pooladian et al. (2023) introduced Multisample Flow Matching, which allows non-independent pairing of noise and data samples within each minibatch. Instead of pairing each $x_0$ with a random $x_1$, they solve a small OT problem between a batch of $n$ samples from $p_0$ and $n$ samples from $p_1$. This yields a coupling (a permutation mapping each noise sample to a specific data sample) that approximately minimizes transport cost for that batch. They then perform flow matching training using those pairs. The overhead of solving an $n\times n$ OT (e.g. via Sinkhorn or linear assignment if $n$ is modest) is small, but the benefits are significant: (i) It reduces gradient variance by ensuring a more consistent target for nearby points, (ii) it produces straighter flows (since each noise sample now aims for a specific data target), enabling high-quality generation with fewer integration steps, and (iii) it learns lower transport-cost maps in high-dimension (useful for tasks beyond generation, like representation learning). Notably, this is still simulation-free and uses the same simple loss objective – the only change is how we sample the training data pairs. Empirically, multisample FM further improves sample consistency and performance on challenging datasets, especially in low-NFE regimes. In essence, Flow Matching via Optimal Transport means incorporating OT principles either by designing $p_{t|0,1}$ as the OT interpolation (if known) or by using techniques like minibatch couplings to approximate the OT path on the fly. Both Rectified Flow and Multisample FM can be seen as efforts toward aligning the flow with the true optimal coupling. The end result is that the learned vector field $u_\theta(t,x)$ more directly implements the optimal transport map from $p_0$ to $p_1$. This yields not only faster sampling but often better mode coverage and generalization, since the network isn't expending capacity on unnecessary "detours". As a concrete example, Lipman et al. mention that using OT paths allowed them to reliably generate ImageNet images with fewer function evaluations than diffusion models, while also achieving higher log-likelihood scores.

Discussion: There is a subtle distinction worth noting: choosing conditional paths that are individually OT (straight line from each $x_0$ to its paired $x_1$) does not guarantee the overall marginal path is the OT between distributions if the pairing is random. That's why independent pairing (even with linear interpolation) may not reach the true OT solution globally. The minibatch coupling addresses this by making the pairing non-trivial. As batch size grows, one approaches the global OT. This highlights how FM provides a flexible framework where we can inject domain knowledge (like OT structure) progressively.

## 5. Schrödinger Bridges and Stochastic Flow Matching

So far we considered deterministic flows (ODEs). Schrödinger Bridges (SB) introduce stochasticity into the picture, generalizing flow matching to diffusion processes. The SB problem is the "most likely" stochastic evolution between a given initial and final distribution under a reference random process. Originally formulated by Schrödinger in 1932, it asks: given $p_0$ and $p_1$, what is the path of a diffusion (e.g. a Brownian motion with drift) that connects them with minimal relative entropy (or equivalently, maximum likelihood relative to an unconstrained Brownian)? In other words, SB finds a probability distribution over paths that is as random as possible while still matching the endpoint distributions. This can be seen as an entropy-regularized optimal transport problem: it seeks to minimize a cost that is the classical transport cost plus a Kullback–Leibler entropy term. The result is a diffusion process (SDE) with a certain drift that ensures $X(0)\sim p_0$ and $X(1)\sim p_1$. SBs bridge the gap between deterministic OT (zero noise) and pure diffusion (maximum noise) by tuning the level of randomness. Why Schrödinger Bridges? Introducing a controlled amount of noise during the transport can make the path easier to realize or compute. Deterministic OT maps in high dimensions can be complex (or even discontinuous for crazy distributions), whereas allowing a bit of diffusion smooths the problem. SBs have drawn attention in machine learning as a way to generalize diffusion models to arbitrary initial distributions, not just Gaussian, and to inject noise in a principled way for dynamic optimal transport. In the context of flow matching, SBs provide a unifying framework: when the diffusion coefficient tends to 0, the SB solution approaches the OT flow; when the diffusion coefficient is large, the SB approaches a pure diffusion model. Thus, SBs let us interpolate between deterministic flow matching and stochastic score-based modeling. Mathematically, solving an SB means finding a drift $u(t,x)$ for an SDE $dX = u(t,X)dt + \sqrt{2\varepsilon},dW_t$ (where $\varepsilon$ is the noise intensity) such that $X(0)\sim p_0$, $X(1)\sim p_1$, and the path distribution minimizes $\mathrm{KL}(P | Q)$ with $Q$ the reference (Brownian motion with variance $\varepsilon$). This is a challenging problem – it translates to a pair of coupled nonlinear PDEs (forward and backward Kolmogorov equations, or Schrödinger system) which resemble a dynamical version of the Sinkhorn algorithm for entropic OT. Until recently, solving SBs required iterative simulations of SDEs or time-consuming optimization in function space. SB via Score and Flow Matching: A breakthrough came by noticing that we can apply simulation-free training to SBs as well. In 2023, multiple works (Tong et al., 2023; Wang et al., 2023, etc.) proposed to unify score matching and flow matching to solve Schrödinger Bridges. Tong et al. introduced a method called [SF]²M (Simulation-Free Score and Flow Matching). The idea is to treat the unknown SB diffusion as something we can learn by composing a score network and a flow network. Roughly, one part of the neural model accounts for the reversible drift (the "flow" component) and another accounts for the added diffusion (the "score" or score-correction component). The training then involves two objectives: one that looks like flow matching (regressing the drift to match an optimal conditional drift), and one that looks like denoising score matching (encouraging consistency with the score of the perturbed data). By combining these, [SF]²M effectively infers the stochastic dynamics of the SB without ever simulating the SDE long-term. A crucial ingredient is using entropic OT to construct the training target. As in deterministic FM, we can sample $(x_0,x_1)$ pairs and an intermediate $x_t$. But now, to decide how $x$ should move and diffuse, the method leverages the entropic OT plan between $p_0$ and $p_1$. Entropic OT (the static Sinkhorn solution) provides a soft coupling between $p_0$ and $p_1$ – essentially a probability $P(x_0,x_1)$ that is the optimal trade-off between matching the marginals and spreading probability (entropy). Tong et al. use this $P(x_0,x_1)$ to sample endpoint pairs more intelligently and to weight the regression terms. In effect, [SF]²M expresses the Schrödinger bridge as a mixture of many Brownian bridges between coupled $x_0$ and $x_1$. Each such Brownian bridge has a known conditional law (much like our Gaussian paths earlier, but now with diffusion noise $\varepsilon$ built in), so one can derive both a drift and a score for the conditional. The neural networks are then trained to match those. This procedure sidesteps having to simulate the SDE repeatedly (hence simulation-free), and experiments show it recovers SB solutions more accurately and efficiently than earlier iterative methods.

How SBs Improve Flow Matching: Schrödinger bridges effectively inject a controlled amount of randomness into the flow. This can make the learned dynamics easier to fit or more stable, especially if $p_0$ and $p_1$ have very disjoint support or complex structures. By tuning the noise level $\varepsilon$, one can attain a sweet spot between a straight but rigid OT path and a flexible but slow diffusion path. In fact, SBs generalize FM: the probability flow ODE of an SB (obtained by setting $\varepsilon$ to the desired level and then removing the noise) is an ODE that one could train via flow matching as well. This means any SB solution corresponds to a family of ODE solutions parameterized by the entropy regularization. Recent work has shown that training an ODE to follow the SB's probability flow yields excellent generative models, sometimes beating pure diffusion or pure flow approaches in sample quality. One can view it as entropy-regularized flow matching. To summarize, incorporating Schrödinger Bridges into flow matching brings the best of both worlds: we retain the efficiency of direct ODE training while allowing some stochastic flexibility to navigate complex spaces. It unifies the theory of diffusion models (score-based modeling) with flow-based modeling under a single optimal transport perspective. This is a cutting-edge area: methods like [SF]²M are actively being developed and have already demonstrated the ability to solve high-dimensional SB problems (e.g. modeling single-cell gene expression dynamics) that were previously infeasible.

## 6. Conclusion (Flow Matching and Beyond)

We have introduced the flow matching framework for generative modeling, starting from its formulation and building up to modern developments. In summary, flow matching trains continuous normalizing flows by regression rather than maximum likelihood, leveraging a cleverly chosen probabilistic interpolation between source and target distributions. It provides a flexible umbrella that covers deterministic flows (CNFs, OT maps), stochastic processes (diffusions, Schrödinger bridges), and everything in between. For a mathematically mature audience, flow matching is appealing because it turns the problem of solving a complicated Fokker–Planck equation (for the unknown generative flow) into a straightforward pointwise regression problem that can be tackled with standard optimization. The use of conditional probability paths is the key trick that makes the target vector field analytically or empirically tractable. We saw that by varying the design of these paths, we recover many known frameworks: Diffusion models appear when using a Gaussian path with large noise (and FM then learns the probability flow ODE of the diffusion); Optimal transport emerges in the zero-noise, straight-line limit (and FM can approximate it via minibatch couplings); Rectified flow explicitly encourages straightness to achieve near-OT trajectories with few steps; and Schrödinger bridges correspond to intermediate noise levels with entropy-regularized coupling, which FM can also capture. All these variations share the common theme of matching flows – either deterministic or stochastic – between distributions. In closing, the flow matching framework provides a powerful lens to view generative modeling. It highlights the continuity between diffusion-based and flow-based methods, and it offers practical algorithms that are faster and often more accurate than their predecessors. As research continues, we expect to see flow matching applied in more contexts (e.g. controlled sequence generation, physics simulations) and further combined with ideas from optimal transport and stochastic control. The result will be generative models that are not only high-quality but also efficient and grounded in rich mathematical theory. References: The concepts discussed here are based on recent works in the literature. For further reading, see Lipman et al. (2023) for the introduction of flow matching, Albergo & Vanden-Eijnden (2023) for stochastic interpolants unifying flows and diffusions, Liu et al. (2023) for rectified flow, Pooladian et al. (2023) for multisample coupling, and Tong et al. (2024) for the Schrödinger bridge approach with score and flow matching. Each of these advances builds on the core ideas of flow matching to push generative modeling towards new frontiers.